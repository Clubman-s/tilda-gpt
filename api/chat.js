import { supabase } from '../lib/supabase'
import { Configuration, OpenAIApi } from 'openai'

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
})

const openai = new OpenAIApi(configuration)

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  const userMessage = req.body.message
  const sessionId = req.body.session_id || 'demo-session'

  if (!userMessage) {
    return res.status(400).json({ error: 'No message provided' })
  }

  // üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
  await supabase.from('messages').insert([
    {
      session_id: sessionId,
      role: 'user',
      content: userMessage,
    }
  ])

  // üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
  const { data: history } = await supabase
    .from('messages')
    .select('*')
    .eq('session_id', sessionId)
    .order('timestamp', { ascending: true })

  const messages = history.map((msg) => ({
    role: msg.role,
    content: msg.content
  }))

  // ‚úâÔ∏è –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ GPT
  const completion = await openai.createChatCompletion({
    model: 'gpt-3.5-turbo',
    messages: messages,
    temperature: 0.7,
  })

  const assistantReply = completion.data.choices[0].message.content

  // üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
  await supabase.from('messages').insert([
    {
      session_id: sessionId,
      role: 'assistant',
      content: assistantReply,
    }
  ])

  // üì§ –û—Ç–¥–∞—ë–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
  res.status(200).json({ reply: assistantReply })
}
